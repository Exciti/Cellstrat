{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ethnicity  Height (CM)  Weight (Kg) Will survive till 70\n",
      "0     White        186.0         90.0                  Yes\n",
      "1   African        185.0         98.0                   No\n",
      "2     White        175.0         80.0                   No\n",
      "3     White        180.0         88.0                  Yes\n",
      "4     Asian        178.0          NaN                   No\n",
      "5     Asian        172.0         72.0                  Yes\n",
      "6   African        178.0         75.0                   No\n",
      "7     White          NaN         89.0                  Yes\n",
      "8   African        186.0         90.0                  Yes\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "CellStrat\n",
    "\"\"\"\n",
    "\n",
    "#==============================================================================\n",
    "# First step to write the python program is to take benefit out of libraries\n",
    "# already available. We will only focus on the data science related libraries.\n",
    "#==============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#==============================================================================\n",
    "# #import data from the data file. In our case its Health.csv. \n",
    "#==============================================================================\n",
    "\n",
    "healthData = pd.read_csv ('Health.csv')\n",
    "print(healthData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['White', 186.0, 90.0],\n",
       "       ['African', 185.0, 98.0],\n",
       "       ['White', 175.0, 80.0],\n",
       "       ['White', 180.0, 88.0],\n",
       "       ['Asian', 178.0, nan],\n",
       "       ['Asian', 172.0, 72.0],\n",
       "       ['African', 178.0, 75.0],\n",
       "       ['White', nan, 89.0],\n",
       "       ['African', 186.0, 90.0]], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# All mathematical operations will be performed on the matrix, so now we create\n",
    "# matrix for dependent variables and independent variables.\n",
    "#==============================================================================\n",
    "\n",
    "\n",
    "X = healthData.iloc [:,:-1].values\n",
    "y = healthData.iloc [:,3].values\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['White' 186.0 90.0]\n",
      " ['African' 185.0 98.0]\n",
      " ['White' 175.0 80.0]\n",
      " ['White' 180.0 88.0]\n",
      " ['Asian' 178.0 88.5]\n",
      " ['Asian' 172.0 72.0]\n",
      " ['African' 178.0 75.0]\n",
      " ['White' 179.0 89.0]\n",
      " ['African' 186.0 90.0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amare\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# Handle the missing values, we can see that in dataset there are some missing\n",
    "# values, we will use strategy to impute mean of column values in these places\n",
    "#==============================================================================\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "# First create an Imputer\n",
    "missingValueImputer = Imputer (missing_values = 'NaN', strategy = 'median',axis = 0)\n",
    "# Set which columns imputer should perform\n",
    "missingValueImputer = missingValueImputer.fit (X[:,1:3])\n",
    "# update values of X with new values\n",
    "X[:,1:3] = missingValueImputer.transform(X[:,1:3])\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 186.0 90.0]\n",
      " [0 185.0 98.0]\n",
      " [2 175.0 80.0]\n",
      " [2 180.0 88.0]\n",
      " [1 178.0 88.5]\n",
      " [1 172.0 72.0]\n",
      " [0 178.0 75.0]\n",
      " [2 179.0 89.0]\n",
      " [0 186.0 90.0]]\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# Encode the categorial data. So now instead of character values we will have\n",
    "# corresponding numerical values\n",
    "#==============================================================================\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# X_labelencoder =\n",
    "X[:,0] =  LabelEncoder().fit_transform(X[:, 0])\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# for y\n",
    "y_labelencoder = LabelEncoder ()\n",
    "y = y_labelencoder.fit_transform (y)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.    0.    1.  186.   90. ]\n",
      " [  1.    0.    0.  185.   98. ]\n",
      " [  0.    0.    1.  175.   80. ]\n",
      " [  0.    0.    1.  180.   88. ]\n",
      " [  0.    1.    0.  178.   88.5]\n",
      " [  0.    1.    0.  172.   72. ]\n",
      " [  1.    0.    0.  178.   75. ]\n",
      " [  0.    0.    1.  179.   89. ]\n",
      " [  1.    0.    0.  186.   90. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amare\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\amare\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# Implementing OneHotEncoder to separate category variables into dummy \n",
    "# variables.\n",
    "#==============================================================================\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X_onehotencoder = OneHotEncoder (categorical_features = [0])\n",
    "X = X_onehotencoder.fit_transform(X).toarray()\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# split the dataset into training and test set. We will use 80/20 approach\n",
    "#==============================================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3,\n",
    "                                                     random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.70710678  1.41421356 -0.70710678 -0.40824829  0.61503402]\n",
      " [ 1.41421356 -0.70710678 -0.70710678  1.22474487  0.81631789]\n",
      " [ 1.41421356 -0.70710678 -0.70710678 -0.40824829 -1.19652074]\n",
      " [-0.70710678 -0.70710678  1.41421356  0.          0.5479394 ]\n",
      " [-0.70710678 -0.70710678  1.41421356  1.22474487  0.81631789]\n",
      " [-0.70710678  1.41421356 -0.70710678 -1.63299316 -1.59908846]]\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# Feature scaling is to bring all the independent variables in a dataset into\n",
    "# same scale, to avoid any variable dominating  the model. Here we will not \n",
    "# transform the dependent variables.\n",
    "#==============================================================================\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "independent_scalar = StandardScaler()\n",
    "X_train = independent_scalar.fit_transform (X_train) #fit and transform\n",
    "X_test = independent_scalar.transform (X_test) # only transform\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
